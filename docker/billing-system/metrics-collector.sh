#!/bin/bash
# metrics-collector.sh - Coleta m√©tricas de uso das inst√¢ncias Supabase
# Executa a cada 5 minutos via cron para coletar dados de uso

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_FILE="${SCRIPT_DIR}/logs/metrics-collector.log"
TEMP_DIR="${SCRIPT_DIR}/temp"

# Configura√ß√£o do banco master
MASTER_DB_URL="${MASTER_DB_URL:-postgresql://postgres:postgres@localhost:5432/supabase_master}"

# Criar diret√≥rios necess√°rios
mkdir -p "$(dirname "$LOG_FILE")" "$TEMP_DIR"

# Fun√ß√£o de log
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Fun√ß√£o para executar query no banco master
query_master() {
    psql "$MASTER_DB_URL" -t -c "$1" 2>/dev/null || echo ""
}

# Fun√ß√£o para executar query em inst√¢ncia espec√≠fica
query_instance() {
    local instance_id="$1"
    local query="$2"
    local port db_url
    
    # Obter porta da inst√¢ncia
    port=$(docker port "${instance_id}_kong" 8000/tcp 2>/dev/null | cut -d: -f2 || echo "")
    
    if [ -z "$port" ]; then
        return 1
    fi
    
    # URL do banco da inst√¢ncia (assumindo padr√£o)
    db_url="postgresql://postgres:postgres@localhost:${port}/postgres"
    
    psql "$db_url" -t -c "$query" 2>/dev/null || echo ""
}

# Fun√ß√£o para obter m√©tricas de uma inst√¢ncia
collect_instance_metrics() {
    local instance_id="$1"
    local project_id="$2"
    local org_id="$3"
    local period_start="$4"
    local period_end="$5"
    
    log "Coletando m√©tricas da inst√¢ncia: $instance_id"
    
    # Verificar se containers est√£o rodando
    if ! docker ps --format "{{.Names}}" | grep -q "^${instance_id}_"; then
        log "‚ö†Ô∏è  Inst√¢ncia $instance_id n√£o est√° rodando"
        return 1
    fi
    
    # 1. M√©tricas de API (via logs do Kong)
    local api_requests=0
    if docker logs "${instance_id}_kong" --since "5m" 2>/dev/null | grep -c "HTTP" >/dev/null 2>&1; then
        api_requests=$(docker logs "${instance_id}_kong" --since "5m" 2>/dev/null | grep "HTTP" | wc -l || echo "0")
    fi
    
    # 2. M√©tricas de storage (via PostgreSQL)
    local storage_bytes=0
    local db_size_query="SELECT pg_database_size(current_database());"
    storage_bytes=$(query_instance "$instance_id" "$db_size_query" | tr -d ' ' || echo "0")
    
    # 3. M√©tricas de bandwidth (estimativa via logs)
    local bandwidth_bytes=0
    if docker logs "${instance_id}_nginx" --since "5m" 2>/dev/null | grep -E "HTTP.*[0-9]+ [0-9]+" >/dev/null 2>&1; then
        bandwidth_bytes=$(docker logs "${instance_id}_nginx" --since "5m" 2>/dev/null | \
            grep -E "HTTP.*[0-9]+ [0-9]+" | \
            awk '{for(i=1;i<=NF;i++) if($i ~ /^[0-9]+$/ && $i > 1000) sum+=$i} END {print sum+0}' || echo "0")
    fi
    
    # 4. Conex√µes de banco ativas
    local db_connections=0
    local connections_query="SELECT count(*) FROM pg_stat_activity WHERE state = 'active';"
    db_connections=$(query_instance "$instance_id" "$connections_query" | tr -d ' ' || echo "0")
    
    # Validar valores num√©ricos
    api_requests=${api_requests//[^0-9]/}
    storage_bytes=${storage_bytes//[^0-9]/}
    bandwidth_bytes=${bandwidth_bytes//[^0-9]/}
    db_connections=${db_connections//[^0-9]/}
    
    # Garantir que valores n√£o estejam vazios
    api_requests=${api_requests:-0}
    storage_bytes=${storage_bytes:-0}
    bandwidth_bytes=${bandwidth_bytes:-0}
    db_connections=${db_connections:-0}
    
    # Inserir m√©tricas no banco master
    local insert_query="
    INSERT INTO usage_metrics (project_id, organization_id, metric_type, value, period_start, period_end)
    VALUES 
        ($project_id, $org_id, 'api_requests', $api_requests, '$period_start', '$period_end'),
        ($project_id, $org_id, 'storage_bytes', $storage_bytes, '$period_start', '$period_end'),
        ($project_id, $org_id, 'bandwidth_bytes', $bandwidth_bytes, '$period_start', '$period_end'),
        ($project_id, $org_id, 'db_connections', $db_connections, '$period_start', '$period_end')
    ON CONFLICT (project_id, metric_type, period_start) DO UPDATE SET
        value = EXCLUDED.value,
        recorded_at = NOW();
    "
    
    if query_master "$insert_query" >/dev/null; then
        log "‚úÖ M√©tricas coletadas: API:$api_requests, Storage:${storage_bytes}bytes, Bandwidth:${bandwidth_bytes}bytes, DB:$db_connections"
    else
        log "‚ùå Erro ao inserir m√©tricas para inst√¢ncia $instance_id"
    fi
}

# Fun√ß√£o para coletar m√©tricas de todas as inst√¢ncias
collect_all_metrics() {
    log "üîç Iniciando coleta de m√©tricas..."
    
    # Definir per√≠odo (√∫ltimos 5 minutos)
    local period_end period_start
    period_end=$(date -u '+%Y-%m-%d %H:%M:00')
    period_start=$(date -u -d '5 minutes ago' '+%Y-%m-%d %H:%M:00')
    
    log "üìä Per√≠odo: $period_start at√© $period_end"
    
    # Buscar todas as inst√¢ncias ativas
    local instances_query="
    SELECT 
        p.instance_id,
        p.id as project_id,
        p.organization_id
    FROM projects p 
    WHERE p.deleted_at IS NULL 
    AND p.instance_id IS NOT NULL
    "
    
    local instances_count=0
    local success_count=0
    
    # Processar cada inst√¢ncia
    while IFS='|' read -r instance_id project_id org_id; do
        if [ -n "$instance_id" ] && [ "$instance_id" != " " ]; then
            instances_count=$((instances_count + 1))
            
            # Remover espa√ßos em branco
            instance_id=$(echo "$instance_id" | tr -d ' ')
            project_id=$(echo "$project_id" | tr -d ' ')
            org_id=$(echo "$org_id" | tr -d ' ')
            
            if collect_instance_metrics "$instance_id" "$project_id" "$org_id" "$period_start" "$period_end"; then
                success_count=$((success_count + 1))
            fi
        fi
    done < <(query_master "$instances_query" | grep -v "^$")
    
    log "üìà Coleta finalizada: $success_count/$instances_count inst√¢ncias processadas"
}

# Fun√ß√£o para limpar m√©tricas antigas
cleanup_old_metrics() {
    log "üßπ Limpando m√©tricas antigas (>30 dias)..."
    
    local cleanup_query="
    DELETE FROM usage_metrics 
    WHERE period_start < NOW() - INTERVAL '30 days';
    "
    
    local deleted_count
    deleted_count=$(query_master "$cleanup_query" | grep "DELETE" | awk '{print $2}' || echo "0")
    
    if [ -n "$deleted_count" ] && [ "$deleted_count" != "0" ]; then
        log "üóëÔ∏è  Removidas $deleted_count m√©tricas antigas"
    fi
}

# Fun√ß√£o para verificar health das inst√¢ncias
check_instances_health() {
    log "üîç Verificando health das inst√¢ncias..."
    
    local total=0
    local healthy=0
    local unhealthy=0
    
    # Buscar todas as inst√¢ncias
    while IFS='|' read -r instance_id project_name; do
        if [ -n "$instance_id" ] && [ "$instance_id" != " " ]; then
            total=$((total + 1))
            instance_id=$(echo "$instance_id" | tr -d ' ')
            project_name=$(echo "$project_name" | tr -d ' ')
            
            # Verificar se containers est√£o rodando
            local containers_running=0
            for service in kong studio db; do
                if docker ps --format "{{.Names}}" | grep -q "^${instance_id}_${service}$"; then
                    containers_running=$((containers_running + 1))
                fi
            done
            
            if [ $containers_running -eq 3 ]; then
                healthy=$((healthy + 1))
                log "‚úÖ $project_name ($instance_id) - Saud√°vel"
            else
                unhealthy=$((unhealthy + 1))
                log "‚ùå $project_name ($instance_id) - $containers_running/3 containers rodando"
            fi
        fi
    done < <(query_master "SELECT instance_id, name FROM projects WHERE deleted_at IS NULL AND instance_id IS NOT NULL" | grep -v "^$")
    
    log "üìä Health check: $healthy saud√°veis, $unhealthy com problemas de $total total"
}

# Fun√ß√£o para gerar relat√≥rio de uso
generate_usage_report() {
    local org_id="${1:-}"
    local output_file="${TEMP_DIR}/usage_report_$(date +%Y%m%d_%H%M%S).json"
    
    log "üìã Gerando relat√≥rio de uso..."
    
    # Query para relat√≥rio
    local report_query="
    SELECT 
        o.name as organization,
        p.name as project,
        p.instance_id,
        metric_type,
        SUM(value) as total_value,
        DATE(period_start) as usage_date
    FROM usage_metrics um
    JOIN projects p ON um.project_id = p.id
    JOIN organizations o ON um.organization_id = o.id
    WHERE um.period_start >= NOW() - INTERVAL '7 days'
    $([ -n "$org_id" ] && echo "AND o.id = $org_id")
    GROUP BY o.name, p.name, p.instance_id, metric_type, DATE(period_start)
    ORDER BY usage_date DESC, organization, project;
    "
    
    if query_master "\\copy ($report_query) TO '$output_file' WITH CSV HEADER;" >/dev/null; then
        log "üìä Relat√≥rio gerado: $output_file"
        return 0
    else
        log "‚ùå Erro ao gerar relat√≥rio"
        return 1
    fi
}

# Fun√ß√£o principal
main() {
    log "üöÄ Iniciando metrics collector..."
    
    # Verificar se o banco master est√° acess√≠vel
    if ! query_master "SELECT 1;" >/dev/null; then
        log "‚ùå N√£o foi poss√≠vel conectar ao banco master"
        exit 1
    fi
    
    # Verificar se Docker est√° rodando
    if ! docker ps >/dev/null 2>&1; then
        log "‚ùå Docker n√£o est√° acess√≠vel"
        exit 1
    fi
    
    # Executar coleta de m√©tricas
    collect_all_metrics
    
    # Executar health check
    check_instances_health
    
    # Limpar m√©tricas antigas (uma vez por dia)
    if [ "$(date +%H%M)" = "0300" ]; then
        cleanup_old_metrics
    fi
    
    log "‚úÖ Coleta de m√©tricas finalizada"
}

# Tratamento de sinais
trap 'log "‚ö†Ô∏è Interrompido pelo usu√°rio"; exit 1' INT TERM

# Verificar argumentos
case "${1:-}" in
    --report)
        generate_usage_report "${2:-}"
        ;;
    --health)
        check_instances_health
        ;;
    --cleanup)
        cleanup_old_metrics
        ;;
    *)
        main
        ;;
esac